check
pyenv --version

start
.venv\Scripts\Activate.ps1
poetry run python scripts/evaluate.py chatgpt_sdgs

PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> pyenv --version
pyenv 3.1.1
PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> .venv\Scripts\Activate.ps1
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> poetry run python scri
chatgpt_meike has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})     
Enter configuration number: 1

################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+-
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP | 
|---------+------+----------------+-----------------+--------------+------------+------+-
| Average | 73.6 |           86.2 |            88.8 |         82.1 |       0.84 | 30.1 | 
| 1       |   77 |           87.0 |            75.8 |         92.6 |       0.83 |   25 | 
| 2       |   69 |           88.4 |            93.0 |         88.9 |       0.91 |   40 | 
| 3       |   76 |           92.1 |            82.4 |        100.0 |       0.90 |   28 | 
| 4       |   82 |           90.2 |            85.7 |         97.7 |       0.91 |   42 | 
| 5       |   69 |           92.8 |            91.7 |         94.3 |       0.93 |   33 | 
| 6       |   85 |           91.8 |            95.6 |         89.6 |       0.92 |   43 | 
| 7       |  100 |           96.0 |            97.9 |         94.0 |       0.96 |   47 | 
| 8       |   74 |           81.1 |            81.6 |         81.6 |       0.82 |   31 | 
| 9       |   57 |           73.7 |            88.2 |         53.6 |       0.67 |   15 | 
| 10      |   61 |           88.5 |            89.3 |         86.2 |       0.88 |   25 | 
| 11      |   69 |           84.1 |            86.4 |         70.4 |       0.78 |   19 | 
| 12      |   80 |           83.8 |            91.7 |         76.7 |       0.84 |   33 | 
| 13      |   65 |           92.3 |            91.2 |         93.9 |       0.93 |   31 | 
| 14      |   84 |           82.1 |            81.2 |         74.3 |       0.78 |   26 | 
| 15      |   71 |           87.3 |            92.1 |         85.4 |       0.89 |   35 | 
| 16      |   68 |           83.8 |            92.9 |         74.3 |       0.83 |   26 | 
| 17      |   64 |           70.3 |            92.9 |         41.9 |       0.58 |   13 | 
+---------+------+----------------+-----------------+--------------+------------+------+-
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> poetry run python scri
chatgpt_meike has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
 7 |
| 13      |   65 |           90.8 |            90.9 |         90.9 |       0.91 |   30 | 
| 14      |   84 |           85.7 |            78.0 |         91.4 |       0.84 |   32 | 
| 15      |   71 |           90.1 |            87.0 |         97.6 |       0.92 |   40 | 
| 16      |   68 |           86.8 |            84.2 |         91.4 |       0.88 |   32 | 
| 17      |   64 |           73.4 |            85.0 |         54.8 |       0.67 |   17 | 
+---------+------+----------------+-----------------+--------------+------------+------+-
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluat
chatgpt_sdgs has several configurations available.
1) Config({'model': 'gpt-4-0125-preview'})
2) Config({'model': 'gpt-3.5-turbo-0125'})
Enter configuration number: 3
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+-
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP | 
|---------+------+----------------+-----------------+--------------+------------+------+-
| Average | 73.6 |           86.2 |            84.1 |         89.4 |       0.86 | 32.6 | 
| 1       |   77 |           79.2 |            62.8 |        100.0 |       0.77 |   27 | 
| 2       |   69 |           91.3 |            97.6 |         88.9 |       0.93 |   40 | 
| 3       |   76 |           90.8 |            81.8 |         96.4 |       0.89 |   27 | 
| 4       |   82 |           84.1 |            76.8 |        100.0 |       0.87 |   43 | 
| 5       |   69 |           91.3 |            89.2 |         94.3 |       0.92 |   33 | 
| 6       |   85 |           94.1 |            93.9 |         95.8 |       0.95 |   46 | 
| 7       |  100 |           97.0 |            94.3 |        100.0 |       0.97 |   50 | 
| 8       |   74 |           78.4 |            73.9 |         89.5 |       0.81 |   34 | 
| 9       |   57 |           86.0 |            88.5 |         82.1 |       0.85 |   23 | 
| 10      |   61 |           85.2 |            91.7 |         75.9 |       0.83 |   22 | 
| 11      |   69 |           84.1 |            76.7 |         85.2 |       0.81 |   23 | 
| 12      |   80 |           85.0 |            83.0 |         90.7 |       0.87 |   39 | 
| 13      |   65 |           95.4 |            91.7 |        100.0 |       0.96 |   33 | 
| 14      |   84 |           85.7 |            78.0 |         91.4 |       0.84 |   32 | 
| 15      |   71 |           85.9 |            91.9 |         82.9 |       0.87 |   34 | 
| 16      |   68 |           77.9 |            72.7 |         91.4 |       0.81 |   32 | 
| 17      |   64 |           73.4 |            85.0 |         54.8 |       0.67 |   17 | 
+---------+------+----------------+-----------------+--------------+------------+------+-
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluat
chatgpt_sdgs has several configurations available.
1) Config({'model': 'gpt-4-0125-preview'})
2) Config({'model': 'gpt-3.5-turbo-0125'})
| 13      |   65 |           95.4 |            91.7 |        100.0 |       0.96 |   33 |    3 |   29 |    0 |
| 14      |   84 |           85.7 |            78.0 |         91.4 |       0.84 |   32 |    9 |   40 |    3 |
| 15      |   71 |           85.9 |            91.9 |         82.9 |       0.87 |   34 |    3 |   27 |    7 |
| 16      |   68 |           77.9 |            72.7 |         91.4 |       0.81 |   32 |   12 |   21 |    3 |
| 17      |   64 |           73.4 |            85.0 |         54.8 |       0.67 |   17 |    3 |   30 |   14 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py gpt_updatedprompt
Traceback (most recent call last):
  File "C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier\scripts\evaluate.py", line 30, in <module>
    Classifier = BaseClassifier.load(args.classifier)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier\classifiers\core\BaseClassifier.py", line 114, in load
    return getattr(module, "Classifier")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'classifiers.gpt_updatedprompt.gpt_updatedprompt' has no attribute 'Classifier'
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike    
chatgpt_meike has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})     
Enter configuration number: 1
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           86.2 |            88.8 |         82.1 |       0.84 | 30.1 |  3.7 | 33.6 |  6.1 |
| 1       |   77 |           87.0 |            75.8 |         92.6 |       0.83 |   25 |    8 |   42 |    2 |
| 2       |   69 |           88.4 |            93.0 |         88.9 |       0.91 |   40 |    3 |   21 |    5 |
| 3       |   76 |           92.1 |            82.4 |        100.0 |       0.90 |   28 |    6 |   42 |    0 |
| 4       |   82 |           90.2 |            85.7 |         97.7 |       0.91 |   42 |    7 |   32 |    1 |
| 5       |   69 |           92.8 |            91.7 |         94.3 |       0.93 |   33 |    3 |   31 |    2 |
| 6       |   85 |           91.8 |            95.6 |         89.6 |       0.92 |   43 |    2 |   35 |    5 |
| 7       |  100 |           96.0 |            97.9 |         94.0 |       0.96 |   47 |    1 |   49 |    3 |
| 8       |   74 |           81.1 |            81.6 |         81.6 |       0.82 |   31 |    7 |   29 |    7 |
| 9       |   57 |           73.7 |            88.2 |         53.6 |       0.67 |   15 |    2 |   27 |   13 |
| 10      |   61 |           88.5 |            89.3 |         86.2 |       0.88 |   25 |    3 |   29 |    4 |
| 11      |   69 |           84.1 |            86.4 |         70.4 |       0.78 |   19 |    3 |   39 |    8 |
| 12      |   80 |           83.8 |            91.7 |         76.7 |       0.84 |   33 |    3 |   34 |   10 |
| 13      |   65 |           92.3 |            91.2 |         93.9 |       0.93 |   31 |    3 |   29 |    2 |
| 14      |   84 |           82.1 |            81.2 |         74.3 |       0.78 |   26 |    6 |   43 |    9 |
| 15      |   71 |           87.3 |            92.1 |         85.4 |       0.89 |   35 |    3 |   27 |    6 |
| 16      |   68 |           83.8 |            92.9 |         74.3 |       0.83 |   26 |    2 |   31 |    9 |
| 17      |   64 |           70.3 |            92.9 |         41.9 |       0.58 |   13 |    1 |   32 |   18 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike
chatgpt_meike has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
Enter configuration number: 1
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           89.3 |            89.1 |         89.3 |       0.89 | 32.5 |    4 | 33.4 |  3.8 |
| 1       |   77 |           85.7 |            72.2 |         96.3 |       0.83 |   26 |   10 |   40 |    1 |
| 2       |   69 |           91.3 |            97.6 |         88.9 |       0.93 |   40 |    1 |   23 |    5 |
| 3       |   76 |           96.1 |            93.1 |         96.4 |       0.95 |   27 |    2 |   46 |    1 |
| 4       |   82 |           91.5 |            86.0 |        100.0 |       0.92 |   43 |    7 |   32 |    0 |
| 5       |   69 |           94.2 |            91.9 |         97.1 |       0.94 |   34 |    3 |   31 |    1 |
| 6       |   85 |           90.6 |            93.5 |         89.6 |       0.91 |   43 |    3 |   34 |    5 |
| 7       |  100 |           96.0 |            96.0 |         96.0 |       0.96 |   48 |    2 |   48 |    2 |
| 8       |   74 |           81.1 |            80.0 |         84.2 |       0.82 |   32 |    8 |   28 |    6 |
| 9       |   57 |           89.5 |            92.3 |         85.7 |       0.89 |   24 |    2 |   27 |    4 |
| 10      |   61 |           88.5 |            89.3 |         86.2 |       0.88 |   25 |    3 |   29 |    4 |
| 11      |   69 |           85.5 |            81.5 |         81.5 |       0.81 |   22 |    5 |   37 |    5 |
| 12      |   80 |           87.5 |            94.6 |         81.4 |       0.88 |   35 |    2 |   35 |    8 |
| 13      |   65 |           95.4 |            91.7 |        100.0 |       0.96 |   33 |    3 |   29 |    0 |
| 14      |   84 |           88.1 |            82.1 |         91.4 |       0.86 |   32 |    7 |   42 |    3 |
| 15      |   71 |           91.5 |            97.3 |         87.8 |       0.92 |   36 |    1 |   29 |    5 |
| 16      |   68 |           85.3 |            80.5 |         94.3 |       0.87 |   33 |    8 |   25 |    2 |
| 17      |   64 |           79.7 |            95.0 |         61.3 |       0.75 |   19 |    1 |   32 |   12 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike_updated
chatgpt_meike_updated has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
Enter configuration number: 1
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           88.4 |            90.3 |         85.9 |       0.87 | 31.4 |  3.4 | 33.9 |  4.9 |
| 1       |   77 |           88.3 |            76.5 |         96.3 |       0.85 |   26 |    8 |   42 |    1 |
| 2       |   69 |           88.4 |            95.1 |         86.7 |       0.91 |   39 |    2 |   22 |    6 |
| 3       |   76 |           96.1 |            93.1 |         96.4 |       0.95 |   27 |    2 |   46 |    1 |
| 4       |   82 |           90.2 |            85.7 |         97.7 |       0.91 |   42 |    7 |   32 |    1 |
| 5       |   69 |           91.3 |            89.2 |         94.3 |       0.92 |   33 |    4 |   30 |    2 |
| 6       |   85 |           92.9 |            95.7 |         91.7 |       0.94 |   44 |    2 |   35 |    4 |
| 7       |  100 |           97.0 |            98.0 |         96.0 |       0.97 |   48 |    1 |   49 |    2 |
| 8       |   74 |           78.4 |            80.6 |         76.3 |       0.78 |   29 |    7 |   29 |    9 |
| 9       |   57 |           84.2 |            91.3 |         75.0 |       0.82 |   21 |    2 |   27 |    7 |
| 10      |   61 |           90.2 |            87.1 |         93.1 |       0.90 |   27 |    4 |   28 |    2 |
| 11      |   69 |           87.0 |            87.5 |         77.8 |       0.82 |   21 |    3 |   39 |    6 |
| 12      |   80 |           87.5 |            97.1 |         79.1 |       0.87 |   34 |    1 |   36 |    9 |
| 13      |   65 |           93.8 |            93.9 |         93.9 |       0.94 |   31 |    2 |   30 |    2 |
| 14      |   84 |           85.7 |            81.1 |         85.7 |       0.83 |   30 |    7 |   42 |    5 |
| 15      |   71 |           94.4 |            97.4 |         92.7 |       0.95 |   38 |    1 |   29 |    3 |
| 16      |   68 |           85.3 |            85.7 |         85.7 |       0.86 |   30 |    5 |   28 |    5 |
| 17      |   64 |           71.9 |           100.0 |         41.9 |       0.59 |   13 |    0 |   33 |   18 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike_updated_all
Tried to load classifier chatgpt_meike_updated_all. But file classifiers/chatgpt_meike_updated_all/chatgpt_meike_updated_all.py does not exist.
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike_updated_all
chatgpt_meike_updated_all has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
Enter configuration number: 1
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           88.4 |            90.3 |         85.9 |       0.87 | 31.4 |  3.4 | 33.9 |  4.9 |
| 1       |   77 |           88.3 |            76.5 |         96.3 |       0.85 |   26 |    8 |   42 |    1 |
| 2       |   69 |           88.4 |            95.1 |         86.7 |       0.91 |   39 |    2 |   22 |    6 |
| 3       |   76 |           96.1 |            93.1 |         96.4 |       0.95 |   27 |    2 |   46 |    1 |
| 4       |   82 |           90.2 |            85.7 |         97.7 |       0.91 |   42 |    7 |   32 |    1 |
| 5       |   69 |           91.3 |            89.2 |         94.3 |       0.92 |   33 |    4 |   30 |    2 |
| 6       |   85 |           92.9 |            95.7 |         91.7 |       0.94 |   44 |    2 |   35 |    4 |
| 7       |  100 |           97.0 |            98.0 |         96.0 |       0.97 |   48 |    1 |   49 |    2 |
| 8       |   74 |           78.4 |            80.6 |         76.3 |       0.78 |   29 |    7 |   29 |    9 |
| 9       |   57 |           84.2 |            91.3 |         75.0 |       0.82 |   21 |    2 |   27 |    7 |
| 10      |   61 |           90.2 |            87.1 |         93.1 |       0.90 |   27 |    4 |   28 |    2 |
| 11      |   69 |           87.0 |            87.5 |         77.8 |       0.82 |   21 |    3 |   39 |    6 |
| 12      |   80 |           87.5 |            97.1 |         79.1 |       0.87 |   34 |    1 |   36 |    9 |
| 13      |   65 |           93.8 |            93.9 |         93.9 |       0.94 |   31 |    2 |   30 |    2 |
| 14      |   84 |           85.7 |            81.1 |         85.7 |       0.83 |   30 |    7 |   42 |    5 |
| 15      |   71 |           94.4 |            97.4 |         92.7 |       0.95 |   38 |    1 |   29 |    3 |
| 16      |   68 |           85.3 |            85.7 |         85.7 |       0.86 |   30 |    5 |   28 |    5 |
| 17      |   64 |           71.9 |           100.0 |         41.9 |       0.59 |   13 |    0 |   33 |   18 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike_updated_all
chatgpt_meike_updated_all has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
Enter configuration number: 1
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           88.7 |            90.2 |         86.3 |       0.87 | 31.5 |  3.4 |   34 |  4.7 |
| 1       |   77 |           88.3 |            76.5 |         96.3 |       0.85 |   26 |    8 |   42 |    1 |
| 2       |   69 |           88.4 |            95.1 |         86.7 |       0.91 |   39 |    2 |   22 |    6 |
| 3       |   76 |           96.1 |            93.1 |         96.4 |       0.95 |   27 |    2 |   46 |    1 |
| 4       |   82 |           90.2 |            85.7 |         97.7 |       0.91 |   42 |    7 |   32 |    1 |
| 5       |   69 |           92.8 |            91.7 |         94.3 |       0.93 |   33 |    3 |   31 |    2 |
| 6       |   85 |           94.1 |            97.8 |         91.7 |       0.95 |   44 |    1 |   36 |    4 |
| 7       |  100 |           97.0 |            98.0 |         96.0 |       0.97 |   48 |    1 |   49 |    2 |
| 8       |   74 |           78.4 |            80.6 |         76.3 |       0.78 |   29 |    7 |   29 |    9 |
| 9       |   57 |           84.2 |            91.3 |         75.0 |       0.82 |   21 |    2 |   27 |    7 |
| 10      |   61 |           90.2 |            89.7 |         89.7 |       0.90 |   26 |    3 |   29 |    3 |
| 11      |   69 |           87.0 |            87.5 |         77.8 |       0.82 |   21 |    3 |   39 |    6 |
| 12      |   80 |           88.8 |            97.2 |         81.4 |       0.89 |   35 |    1 |   36 |    8 |
| 13      |   65 |           95.4 |            94.1 |         97.0 |       0.96 |   32 |    2 |   30 |    1 |
| 14      |   84 |           86.9 |            81.6 |         88.6 |       0.85 |   31 |    7 |   42 |    4 |
| 15      |   71 |           93.0 |            95.0 |         92.7 |       0.94 |   38 |    2 |   28 |    3 |
| 16      |   68 |           86.8 |            86.1 |         88.6 |       0.87 |   31 |    5 |   28 |    4 |
| 17      |   64 |           70.3 |            92.9 |         41.9 |       0.58 |   13 |    1 |   32 |   18 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike
chatgpt_meike has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
Enter configuration number: 1
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           89.3 |            89.1 |         89.3 |       0.89 | 32.5 |    4 | 33.4 |  3.8 |
| 1       |   77 |           85.7 |            72.2 |         96.3 |       0.83 |   26 |   10 |   40 |    1 |
| 2       |   69 |           91.3 |            97.6 |         88.9 |       0.93 |   40 |    1 |   23 |    5 |
| 3       |   76 |           96.1 |            93.1 |         96.4 |       0.95 |   27 |    2 |   46 |    1 |
| 4       |   82 |           91.5 |            86.0 |        100.0 |       0.92 |   43 |    7 |   32 |    0 |
| 5       |   69 |           94.2 |            91.9 |         97.1 |       0.94 |   34 |    3 |   31 |    1 |
| 6       |   85 |           90.6 |            93.5 |         89.6 |       0.91 |   43 |    3 |   34 |    5 |
| 7       |  100 |           96.0 |            96.0 |         96.0 |       0.96 |   48 |    2 |   48 |    2 |
| 8       |   74 |           81.1 |            80.0 |         84.2 |       0.82 |   32 |    8 |   28 |    6 |
| 9       |   57 |           89.5 |            92.3 |         85.7 |       0.89 |   24 |    2 |   27 |    4 |
| 10      |   61 |           88.5 |            89.3 |         86.2 |       0.88 |   25 |    3 |   29 |    4 |
| 11      |   69 |           85.5 |            81.5 |         81.5 |       0.81 |   22 |    5 |   37 |    5 |
| 12      |   80 |           87.5 |            94.6 |         81.4 |       0.88 |   35 |    2 |   35 |    8 |
| 13      |   65 |           95.4 |            91.7 |        100.0 |       0.96 |   33 |    3 |   29 |    0 |
| 14      |   84 |           88.1 |            82.1 |         91.4 |       0.86 |   32 |    7 |   42 |    3 |
| 15      |   71 |           91.5 |            97.3 |         87.8 |       0.92 |   36 |    1 |   29 |    5 |
| 16      |   68 |           85.3 |            80.5 |         94.3 |       0.87 |   33 |    8 |   25 |    2 |
| 17      |   64 |           79.7 |            95.0 |         61.3 |       0.75 |   19 |    1 |   32 |   12 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike
chatgpt_meike has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
Enter configuration number: 2
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           86.1 |            79.5 |         97.2 |       0.87 | 35.2 |    9 | 28.4 |  1.1 |
| 1       |   77 |           88.3 |            75.0 |        100.0 |       0.86 |   27 |    9 |   41 |    0 |
| 2       |   69 |           92.8 |            93.5 |         95.6 |       0.95 |   43 |    3 |   21 |    2 |
| 3       |   76 |           89.5 |            79.4 |         96.4 |       0.87 |   27 |    7 |   41 |    1 |
| 4       |   82 |           85.4 |            78.2 |        100.0 |       0.88 |   43 |   12 |   27 |    0 |
| 5       |   69 |           91.3 |            85.4 |        100.0 |       0.92 |   35 |    6 |   28 |    0 |
| 6       |   85 |           92.9 |            90.4 |         97.9 |       0.94 |   47 |    5 |   32 |    1 |
| 7       |  100 |           92.0 |            86.2 |        100.0 |       0.93 |   50 |    8 |   42 |    0 |
| 8       |   74 |           77.0 |            72.3 |         89.5 |       0.80 |   34 |   13 |   23 |    4 |
| 9       |   57 |           82.5 |            75.0 |         96.4 |       0.84 |   27 |    9 |   20 |    1 |
| 10      |   61 |           80.3 |            70.7 |        100.0 |       0.83 |   29 |   12 |   20 |    0 |
| 11      |   69 |           82.6 |            69.2 |        100.0 |       0.82 |   27 |   12 |   30 |    0 |
| 12      |   80 |           86.2 |            86.4 |         88.4 |       0.87 |   38 |    6 |   31 |    5 |
| 13      |   65 |           93.8 |            89.2 |        100.0 |       0.94 |   33 |    4 |   28 |    0 |
| 14      |   84 |           82.1 |            70.8 |         97.1 |       0.82 |   34 |   14 |   35 |    1 |
| 15      |   71 |           87.3 |            82.0 |        100.0 |       0.90 |   41 |    9 |   21 |    0 |
| 16      |   68 |           72.1 |            65.4 |         97.1 |       0.78 |   34 |   18 |   15 |    1 |
| 17      |   64 |           87.5 |            82.9 |         93.5 |       0.88 |   29 |    6 |   27 |    2 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed
################################################################################
(.venv) PS C:\Users\Gebruiker\Documents\GitHub\llm-sdg-classifier> python scripts/evaluate.py chatgpt_meike_updated_all
chatgpt_meike_updated_all has several configurations available.
1) Config({'model': 'gpt-4o-mini'})
2) Config({'model': 'gpt-4o'})
3) Config({'model': 'gpt-4-turbo'})
Enter configuration number: 2
################################################################################
Running benchmark
Benchmarking |################################| 1251/1251
Results:
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
| SDG     |    n |   Accuracy (%) |   Precision (%) |   Recall (%) |   F1 Score |   TP |   FP |   TN |   FN |
|---------+------+----------------+-----------------+--------------+------------+------+------+------+------|
| Average | 73.6 |           88.2 |            86.8 |         89.6 |       0.88 | 32.6 |  4.9 | 32.5 |  3.6 |
| 1       |   77 |           90.9 |            81.2 |         96.3 |       0.88 |   26 |    6 |   44 |    1 |
| 2       |   69 |           89.9 |            93.2 |         91.1 |       0.92 |   41 |    3 |   21 |    4 |
| 3       |   76 |           90.8 |            86.2 |         89.3 |       0.88 |   25 |    4 |   44 |    3 |
| 4       |   82 |           89.0 |            84.0 |         97.7 |       0.90 |   42 |    8 |   31 |    1 |
| 5       |   69 |           87.0 |            88.2 |         85.7 |       0.87 |   30 |    4 |   30 |    5 |
| 6       |   85 |           95.3 |            94.0 |         97.9 |       0.96 |   47 |    3 |   34 |    1 |
| 7       |  100 |           98.0 |            96.2 |        100.0 |       0.98 |   50 |    2 |   48 |    0 |
| 8       |   74 |           81.1 |            81.6 |         81.6 |       0.82 |   31 |    7 |   29 |    7 |
| 9       |   57 |           87.7 |            86.2 |         89.3 |       0.88 |   25 |    4 |   25 |    3 |
| 10      |   61 |           95.1 |            96.4 |         93.1 |       0.95 |   27 |    1 |   31 |    2 |
| 11      |   69 |           87.0 |            78.1 |         92.6 |       0.85 |   25 |    7 |   35 |    2 |
| 12      |   80 |           86.2 |            92.1 |         81.4 |       0.86 |   35 |    3 |   34 |    8 |
| 13      |   65 |           92.3 |            93.8 |         90.9 |       0.92 |   30 |    2 |   30 |    3 |
| 14      |   84 |           85.7 |            76.7 |         94.3 |       0.85 |   33 |   10 |   39 |    2 |
| 15      |   71 |           84.5 |            82.6 |         92.7 |       0.87 |   38 |    8 |   22 |    3 |
| 16      |   68 |           83.8 |            80.0 |         91.4 |       0.85 |   32 |    8 |   25 |    3 |
| 17      |   64 |           75.0 |            85.7 |         58.1 |       0.69 |   18 |    3 |   30 |   13 |
+---------+------+----------------+-----------------+--------------+------------+------+------+------+------+
Benchmark completed